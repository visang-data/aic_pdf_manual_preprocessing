import streamlit as st
import os
import re
import fitz  # PyMuPDF
import base64
import time
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configuration
# Configuration
VLLM_BASE_URL = os.getenv("VLLM_API_BASE", "http://notebook-nlb-f68504b00671f364.elb.ap-northeast-2.amazonaws.com:8503/v1")
VLLM_MODEL = os.getenv("VLLM_MODEL", "qwen3-vl-32b-thinking")
VLLM_API_KEY = os.getenv("VLLM_API_KEY", "EMPTY")
PDF_DATA_DIR = "test_pdf_data"

# Default Prompts (Matches CLI)
SYSTEM_PROMPT_DEFAULT = """ë‹¹ì‹ ì€ ê¸°ì—…ì˜ **ëª¨ë“  ì‚¬ë‚´ ì—…ë¬´ ë§¤ë‰´ì–¼(Internal Business Manuals)**ì„ í…ìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ë¡œ êµ¬ì¶•í•˜ëŠ” **ì „ë¬¸ í…Œí¬ë‹ˆì»¬ ë¼ì´í„°(Technical Writer)**ì…ë‹ˆë‹¤.
ì£¼ì–´ì§€ëŠ” ì´ë¯¸ì§€ëŠ” ì¸ì‚¬ ê·œì •,  IT ê°€ì´ë“œ, ì¬ë¬´ ë³´ê³ ì„œ, ì•ˆì „ ìˆ˜ì¹™, ìš´ì˜ ì ˆì°¨ì„œ(SOP) ë“± ë‹¤ì–‘í•œ ì‚¬ë‚´ ë¬¸ì„œì˜ í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì´ë¯¸ì§€ ë‚´ì˜ ì •ë³´ë¥¼ ì‹œê°ì  ìš”ì†Œ ì—†ì´ ì˜¤ì§ **'ì—…ë¬´ì  ì˜ë¯¸'ì™€ 'ì‹¤ì§ˆì  ë‚´ìš©'**ì— ì§‘ì¤‘í•˜ì—¬ êµ¬ì¡°í™”ëœ Markdown ë¬¸ì„œë¡œ ì™„ë²½í•˜ê²Œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë‹¤ìŒì˜ **[ì‘ì„± ì›ì¹™]**ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤:

### 1. ì‹œê°ì  ë¬˜ì‚¬ ë°°ì œ (Context Over Visuals)
- **ì ˆëŒ€ ê¸ˆì§€:** ìƒ‰ìƒ, ë°°ì¹˜, ì•„ì´ì½˜ ëª¨ì–‘, ì¥ì‹ì  ì´ë¯¸ì§€ ë“± ë””ìì¸ ìš”ì†Œì— ëŒ€í•œ ë¬˜ì‚¬ëŠ” í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- **ìˆ˜í–‰ ì§€ì¹¨:** í•´ë‹¹ ì´ë¯¸ì§€ê°€ ì—…ë¬´ ìˆ˜í–‰ì„ ìœ„í•´ ì „ë‹¬í•˜ê³ ì í•˜ëŠ” **í•µì‹¬ ë©”ì‹œì§€, ê·œì •, ë°ì´í„°**ë§Œì„ í…ìŠ¤íŠ¸ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.

### 2. ë¹„ì •í˜• ë°ì´í„°ì˜ ë…¼ë¦¬ì  ë³€í™˜
- **UI/ìŠ¤í¬ë¦°ìƒ· (ì‹œìŠ¤í…œ í™”ë©´):** ë‹¨ìˆœí•œ í™”ë©´ ë¬˜ì‚¬ê°€ ì•„ë‹Œ, ì‚¬ìš©ìê°€ ë”°ë¼ì•¼ í•  **'ì‘ì—… ì ˆì°¨(Actionable Steps)'**ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ì €ì¥ ì•„ì´ì½˜" -> "1. [ì €ì¥] ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë³€ê²½ ì‚¬í•­ì„ ë°˜ì˜í•©ë‹ˆë‹¤.")
- **ë„ì‹/ë‹¤ì´ì–´ê·¸ë¨ (êµ¬ì¡° ë° ê´€ê³„):** ì¡°ì§ë„, êµ¬ì„±ë„, ë„¤íŠ¸ì›Œí¬ ë§µ ë“±ì˜ ì‹œê°ì  ê´€ê³„ë¥¼ **ê³„ì¸µí˜• ë¦¬ìŠ¤íŠ¸(Bulleted List)**ë‚˜ **ë…¼ë¦¬ì  ì„œìˆ **ë¡œ í’€ì–´ë‚´ì‹­ì‹œì˜¤.
- **íë¦„ë„ (í”„ë¡œì„¸ìŠ¤):** ì—…ë¬´ íë¦„ì´ë‚˜ ê²°ì¬ ë¼ì¸ ë“±ì˜ í™”ì‚´í‘œ íë¦„ì„ **'ìˆœì„œ(Step 1, 2...)'** ë˜ëŠ” **'ì¡°ê±´(If-Then)'** ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.

### 3. í‘œ(Table) ë°ì´í„° ì²˜ë¦¬
- **ë°ì´í„° í‘œ:** ê·œì • ìˆ˜ì¹˜, ìŠ¤í™(Spec), ìš”ìœ¨í‘œ, ì¼ì • ë“± ì •í™•í•œ ê°’ì´ ì¤‘ìš”í•œ í‘œëŠ” ë°˜ë“œì‹œ **Markdown Table** ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
- **ë ˆì´ì•„ì›ƒìš© í‘œ:** ë‹¨ìˆœíˆ ë°°ì¹˜ë¥¼ ìœ„í•´ ì‚¬ìš©ëœ í‘œëŠ” í…ìŠ¤íŠ¸ì˜ íë¦„ì— ë§ê²Œ ë¬¸ì¥ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ë¡œ í’€ì–´ì„œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

### 4. ë¬¸ì„œ êµ¬ì¡°í™” (Formatting)
- ë¬¸ì„œì˜ ìœ„ê³„(ì¥, ì ˆ, í•­)ë¥¼ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ **Markdown Header (#, ##, ###)**ë¥¼ ì ìš©í•˜ì‹­ì‹œì˜¤.
- ë³¸ë¬¸ ë‚´ìš©ì€ ëª…í™•í•œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì‹­ì‹œì˜¤."""

USER_PROMPT_DEFAULT = """ì œê³µëœ ë§¤ë‰´ì–¼ í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì—¬ DB ì ì¬ë¥¼ ìœ„í•œ **ì™„ë²½í•œ Markdown í¬ë§·**ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

**[í•„ìˆ˜ ìˆ˜í–‰ ê³¼ì œ]**
1. **ì™„ì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ:** í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  ì—…ë¬´ ê´€ë ¨ í…ìŠ¤íŠ¸(ë³¸ë¬¸, ì£¼ì„, ìº¡ì…˜ í¬í•¨)ë¥¼ ëˆ„ë½ ì—†ì´ ì „ì‚¬í•˜ì‹­ì‹œì˜¤.
2. **êµ¬ì¡°ì  ëª…ì‹œ:** ì œëª©(#)ê³¼ ë³¸ë¬¸, ë¦¬ìŠ¤íŠ¸(-)ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
3. **ë¶ˆí•„ìš”í•œ ë§ ìƒëµ:** "ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤"ì™€ ê°™ì€ ì„œë‘ë‚˜ ë§ºìŒë§ ì—†ì´, ì˜¤ì§ **Markdown ë³¸ë¬¸ ë‚´ìš©**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤."""



# Page Configuration
st.set_page_config(
    page_title="PDF Preprocessing with Qwen-VL",
    page_icon="ğŸ‘ï¸",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; color: #333; }
    .stButton > button { border-radius: 8px; }
    .reportview-container { margin-top: -2em; }
    #MainMenu {visibility: hidden;}
    .stDeployButton {display:none;}
    footer {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

def get_base64_image(pix):
    """Convert PyMuPDF binary data to base64 string"""
    data = pix.tobytes("jpg", jpg_quality=90)
    return base64.b64encode(data).decode('utf-8')

def parse_model_output(text):
    """
    Parse LLM output to separate <think>...</think> blocks from the actual response.
    Returns (thinking_content, response_content).
    """
    if not text:
        return "", ""
    
    # Check for thinking end tag FIRST (as per CLI robust fix)
    if '</think>' in text:
        parts = text.split('</think>')
        thinking = parts[0].replace('<think>', '').strip()
        response = parts[-1].strip()
        return thinking, response
        
    # Fallback to regex
    thinking_match = re.search(r'<think>(.*?)</think>', text, flags=re.IGNORECASE | re.DOTALL)
    thinking = thinking_match.group(1).strip() if thinking_match else ""
    
    response = re.sub(r'<think>.*?</think>', '', text, flags=re.IGNORECASE | re.DOTALL).strip()
    
    return thinking, response

def process_page_with_qwen(system_prompt, user_prompt, base64_image, previous_context=""):
    """
    Returns a stream object from OpenAI client.
    """
    client = OpenAI(
        api_key=VLLM_API_KEY,
        base_url=VLLM_BASE_URL,
    )
    
    # Initialize list
    final_user_prompt_content = []

    # --- DEBUG LOGGING ---
    print("\n" + "="*50)
    print(f"ğŸš€ Processing Page (Context: {'Yes' if previous_context else 'No'})")
    print(f"ğŸ“· Image Size: {len(base64_image)} chars")
    
    # 1. Add Context (Previous Page)
    if previous_context:
        print(f"ğŸ”— Context Injected ({len(previous_context)} chars)")
        context_block = f"**[ì´ì „ í˜ì´ì§€ ë‚´ìš© (ë¬¸ë§¥ ìœ ì§€ìš©)]**\n{previous_context[-2000:]}\n\n**[ì§€ì‹œì‚¬í•­]**\nìœ„ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬, ë‹¤ìŒ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ì´ì–´ì§€ëŠ” í˜•íƒœë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì‹œì˜¤."
        final_user_prompt_content.append({"type": "text", "text": context_block})
        
    # 2. Add Main Prompt & Image
    print(f"ğŸ“ User Prompt: {user_prompt[:100]}...")
    final_user_prompt_content.append({"type": "text", "text": user_prompt})
    final_user_prompt_content.append({
        "type": "image_url",
        "image_url": {
            "url": f"data:image/png;base64,{base64_image}"
        },
    })

    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": final_user_prompt_content,
        }
    ]

    # Extra body for thinking mode (if needed by model/vllm)
    extra_body = {
        "chat_template_kwargs": {"enable_thinking": True}
    }

    try:
        print("â³ Sending request to VLLM (Stream Mode)...")
        # Ensure stream=True
        stream = client.chat.completions.create(
            model=VLLM_MODEL,
            messages=messages,
            temperature=0.0,
            max_tokens=8192,
            extra_body=extra_body,
            stream=True
        )
        return stream
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def list_pdf_files():
    if not os.path.exists(PDF_DATA_DIR):
        os.makedirs(PDF_DATA_DIR)
        return []
    return [f for f in os.listdir(PDF_DATA_DIR) if f.lower().endswith('.pdf')]

def render_pdf_page(pdf_path, page_num, target_long_side=1280):
    """
    Render a page to a target pixel size (long side).
    Ensures doc is closed to prevent memory leaks.
    """
    doc = fitz.open(pdf_path)
    try:
        page = doc.load_page(page_num)
        
        # Calculate zoom to match target_long_side
        page_w, page_h = page.rect.width, page.rect.height
        max_dim = max(page_w, page_h)
        
        # Avoid dividing by zero and ensure target size
        if max_dim > 0:
            zoom = target_long_side / max_dim
        else:
            zoom = 1.0
            
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat)
        return pix
    finally:
        doc.close()

def main():
    st.title("ğŸ‘ï¸ Visual PDF Preprocessor")
    st.markdown("Convert PDF pages to rich text (context + visual descriptions) using Qwen-VL.")

    # Sidebar Settings
    with st.sidebar:
        st.header("âš™ï¸ Settings")
        
        # File Selection
        pdf_files = list_pdf_files()
        uploaded_file = st.file_uploader("Upload New PDF", type="pdf")
        
        selected_pdf_name = st.selectbox(
            "Select PDF from 'test_pdf_data'", 
            options=["-- Select --"] + pdf_files
        )

        current_pdf_path = None
        if uploaded_file:
            # Save uploaded file to temp path or data dir
            save_path = os.path.join(PDF_DATA_DIR, uploaded_file.name)
            with open(save_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            current_pdf_path = save_path
            st.success(f"Saved {uploaded_file.name}")
            # Refresh list workaround or just use this path
        elif selected_pdf_name != "-- Select --":
            current_pdf_path = os.path.join(PDF_DATA_DIR, selected_pdf_name)

        st.divider()
        
        if st.button("ğŸš€ Process Entire Document", type="primary", use_container_width=True):
             st.session_state['batch_processing'] = True
             st.session_state['combined_result'] = "" # Reset

    if not current_pdf_path:
        st.info("ğŸ‘ˆ Please select or upload a PDF to start.")
        return

    # --- Main Content Area ---
    
    # Prompt Configuration (Prominent)
    st.header("ğŸ“ Prompt Configuration")
    st.markdown("These prompts control how the VLM interprets and translates your PDF pages.")
    
    col_sys, col_user = st.columns(2)
    with col_sys:
        system_prompt = st.text_area(
            "System Prompt",
            value=SYSTEM_PROMPT_DEFAULT,
            height=450
        )
    with col_user:
        user_prompt = st.text_area(
            "User Prompt",
            value=USER_PROMPT_DEFAULT,
            height=450
        )
    
    st.divider()

    # --- Document Processing ---
    doc = fitz.open(current_pdf_path)
    total_pages = len(doc)
    doc.close()

    # Check if batch processing was triggered
    if st.session_state.get('batch_processing', False):
        st.subheader("ğŸ“š Batch Processing")
        progress_bar = st.progress(0)
        status_text = st.empty()
        combined_text = ""
        
        last_page_text = ""
        
        for i in range(total_pages):
            status_text.text(f"Processing Page {i+1}/{total_pages}...")
            
            pix = render_pdf_page(current_pdf_path, i)
            base64_img = get_base64_image(pix)
            
            # Create a container for this page's result
            with st.container():
                st.markdown(f"### Page {i+1}")
                cols = st.columns([1, 2])
                
                # Column 1: Thumbnail
                with cols[0]:
                    st.image(pix.tobytes("jpg", jpg_quality=90), caption=f"Page {i+1}", use_container_width=True)
                
                # Column 2: Processing...
                with cols[1]:
                    # Create UI elements for streaming
                    thinking_expander = st.expander("ğŸ§  Thinking Process", expanded=True)
                    thinking_placeholder = thinking_expander.empty()
                    
                    st.markdown("**ğŸ“„ Extracted Content:**")
                    response_placeholder = st.empty()
                    
                    # Prepare for streaming
                    full_thinking = ""
                    full_response = ""
                    current_mode = "thinking" # thinking | response
                    
                    # Start Stream
                    stream = process_page_with_qwen(system_prompt, user_prompt, base64_img, previous_context=last_page_text)
                    
                    if stream:
                        for chunk in stream:
                            # Safely get content delta
                            if chunk.choices and chunk.choices[0].delta.content:
                                content = chunk.choices[0].delta.content
                                
                                # Check for transition: </think>
                                if "</think>" in content:
                                    parts = content.split("</think>")
                                    
                                    # First part goes to thinking
                                    full_thinking += parts[0]
                                    thinking_placeholder.code(full_thinking.replace("<think>", "").strip(), language='text')
                                    
                                    # Switch mode
                                    current_mode = "response"
                                    
                                    # Second part goes to response
                                    if len(parts) > 1:
                                        full_response += parts[1]
                                        response_placeholder.markdown(full_response + "â–Œ")
                                        
                                    # Collapse thinking after done
                                    # thinking_expander.update(expanded=False) # Not directly possible in streamlit loop easily without rerun, ignore
                                    
                                else:
                                    if current_mode == "thinking":
                                        full_thinking += content
                                        # Only update thinking occasionally or it flickers? code block handles it well
                                        thinking_placeholder.code(full_thinking.replace("<think>", "").strip() + "â–Œ", language='text')
                                    else:
                                        full_response += content
                                        response_placeholder.markdown(full_response + "â–Œ")
                                        
                        # Final update to remove cursor
                        if current_thinking := full_thinking.replace("<think>", "").strip():
                            thinking_placeholder.code(current_thinking, language='text')
                        response_placeholder.markdown(full_response)
                        
                        # Set page result for next loop/storage
                        page_result = full_response
                        thinking = full_thinking
                    else:
                        st.error("Failed to connect to model.")
                        page_result = ""
            
            st.divider()
            
            combined_text += f"\n\n--- Page {i+1} ---\n\n"
            combined_text += page_result
            
            # Update last_page_text for next iteration context
            last_page_text = page_result
            
            progress_bar.progress((i + 1) / total_pages)
        
        st.session_state['combined_result'] = combined_text
        st.session_state['batch_processing'] = False
        status_text.success("Batch processing complete!")
        st.rerun()

    # Display Results
    if 'combined_result' in st.session_state and st.session_state['combined_result']:
        st.subheader("ğŸ“‘ Combined Document Output")
        st.text_area("Full Document Markdown", value=st.session_state['combined_result'], height=800)
        
        if st.button("ğŸ’¾ Save All to .txt"):
            output_filename = f"processed_{os.path.basename(current_pdf_path).replace('.pdf', '')}_FULL.txt"
            with open(os.path.join(PDF_DATA_DIR, output_filename), "w") as f:
                f.write(st.session_state['combined_result'])
            st.success(f"Saved to {output_filename}")
            
        if st.button(" Clear Results"):
             del st.session_state['combined_result']
             st.rerun()
    else:
        # Show preview when no results yet
        st.subheader(f"ğŸ“„ Document Preview ({total_pages} pages)")
        page_num = st.slider("Preview Page", min_value=1, max_value=total_pages, value=1) - 1
        pix = render_pdf_page(current_pdf_path, page_num)
        st.image(pix.tobytes("jpg", jpg_quality=90), caption=f"Page {page_num + 1} / {total_pages}", use_container_width=True)

if __name__ == "__main__":
    main()