import streamlit as st
import os
import re
import fitz  # PyMuPDF
import base64
import time
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configuration
# Configuration
VLLM_BASE_URL = os.getenv("VLLM_API_BASE", "http://notebook-nlb-f68504b00671f364.elb.ap-northeast-2.amazonaws.com:8503/v1")
VLLM_MODEL = os.getenv("VLLM_MODEL", "qwen3-vl-32b-thinking")
VLLM_API_KEY = os.getenv("VLLM_API_KEY", "EMPTY")
PDF_DATA_DIR = "test_pdf_data"

# Default Prompts (Matches CLI)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê¸°ì—…ì˜ **ëª¨ë“  ì‚¬ë‚´ ì—…ë¬´ ë§¤ë‰´ì–¼(Internal Business Manuals)**ì„ í…ìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ë¡œ êµ¬ì¶•í•˜ëŠ” **ì „ë¬¸ í…Œí¬ë‹ˆì»¬ ë¼ì´í„°(Technical Writer)**ì…ë‹ˆë‹¤.
ì£¼ì–´ì§€ëŠ” ì´ë¯¸ì§€ëŠ” ì¸ì‚¬ ê·œì •,  IT ê°€ì´ë“œ, ì¬ë¬´ ë³´ê³ ì„œ, ì•ˆì „ ìˆ˜ì¹™, ìš´ì˜ ì ˆì°¨ì„œ(SOP) ë“± ë‹¤ì–‘í•œ ì‚¬ë‚´ ë¬¸ì„œì˜ í•œ í˜ì´ì§€ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì´ë¯¸ì§€ ë‚´ì˜ ì •ë³´ë¥¼ ì‹œê°ì  ìš”ì†Œ ì—†ì´ ì˜¤ì§ **'ì—…ë¬´ì  ì˜ë¯¸'ì™€ 'ì‹¤ì§ˆì  ë‚´ìš©'**ì— ì§‘ì¤‘í•˜ì—¬ êµ¬ì¡°í™”ëœ Markdown ë¬¸ì„œë¡œ ì™„ë²½í•˜ê²Œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë‹¤ìŒì˜ **[ì‘ì„± ì›ì¹™]**ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤:

### 1. ì‹œê°ì  ë¬˜ì‚¬ ë°°ì œ (Context Over Visuals)
- **ì ˆëŒ€ ê¸ˆì§€:** ìƒ‰ìƒ, ë°°ì¹˜, ì•„ì´ì½˜ ëª¨ì–‘, ì¥ì‹ì  ì´ë¯¸ì§€ ë“± ë””ìì¸ ìš”ì†Œì— ëŒ€í•œ ë¬˜ì‚¬ëŠ” í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- **ìˆ˜í–‰ ì§€ì¹¨:** í•´ë‹¹ ì´ë¯¸ì§€ê°€ ì—…ë¬´ ìˆ˜í–‰ì„ ìœ„í•´ ì „ë‹¬í•˜ê³ ì í•˜ëŠ” **í•µì‹¬ ë©”ì‹œì§€, ê·œì •, ë°ì´í„°**ë§Œì„ í…ìŠ¤íŠ¸ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.

### 2. ë¹„ì •í˜• ë°ì´í„°ì˜ ë…¼ë¦¬ì  ë³€í™˜
- **UI/ìŠ¤í¬ë¦°ìƒ· (ì‹œìŠ¤í…œ í™”ë©´):** ë‹¨ìˆœí•œ í™”ë©´ ë¬˜ì‚¬ê°€ ì•„ë‹Œ, ì‚¬ìš©ìê°€ ë”°ë¼ì•¼ í•  **'ì‘ì—… ì ˆì°¨(Actionable Steps)'**ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ì €ì¥ ì•„ì´ì½˜" -> "1. [ì €ì¥] ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë³€ê²½ ì‚¬í•­ì„ ë°˜ì˜í•©ë‹ˆë‹¤.")
- **ë„ì‹/ë‹¤ì´ì–´ê·¸ë¨ (êµ¬ì¡° ë° ê´€ê³„):** ì¡°ì§ë„, êµ¬ì„±ë„, ë„¤íŠ¸ì›Œí¬ ë§µ ë“±ì˜ ì‹œê°ì  ê´€ê³„ë¥¼ **ê³„ì¸µí˜• ë¦¬ìŠ¤íŠ¸(Bulleted List)**ë‚˜ **ë…¼ë¦¬ì  ì„œìˆ **ë¡œ í’€ì–´ë‚´ì‹­ì‹œì˜¤.
- **íë¦„ë„ (í”„ë¡œì„¸ìŠ¤):** ì—…ë¬´ íë¦„ì´ë‚˜ ê²°ì¬ ë¼ì¸ ë“±ì˜ í™”ì‚´í‘œ íë¦„ì„ **'ìˆœì„œ(Step 1, 2...)'** ë˜ëŠ” **'ì¡°ê±´(If-Then)'** ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.

### 3. í‘œ(Table) ë°ì´í„° ì²˜ë¦¬
- **ë°ì´í„° í‘œ:** ê·œì • ìˆ˜ì¹˜, ìŠ¤í™(Spec), ìš”ìœ¨í‘œ, ì¼ì • ë“± ì •í™•í•œ ê°’ì´ ì¤‘ìš”í•œ í‘œëŠ” ë°˜ë“œì‹œ **Markdown Table** ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
- **ë ˆì´ì•„ì›ƒìš© í‘œ:** ë‹¨ìˆœíˆ ë°°ì¹˜ë¥¼ ìœ„í•´ ì‚¬ìš©ëœ í‘œëŠ” í…ìŠ¤íŠ¸ì˜ íë¦„ì— ë§ê²Œ ë¬¸ì¥ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ë¡œ í’€ì–´ì„œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

### 4. ë¬¸ì„œ êµ¬ì¡°í™” (Formatting)
- ë¬¸ì„œì˜ ìœ„ê³„(ì¥, ì ˆ, í•­)ë¥¼ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ **Markdown Header (#, ##, ###)**ë¥¼ ì ìš©í•˜ì‹­ì‹œì˜¤.
- ë³¸ë¬¸ ë‚´ìš©ì€ ëª…í™•í•œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì‹­ì‹œì˜¤."""

USER_PROMPT = """ì œê³µëœ ë§¤ë‰´ì–¼ í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì—¬ DB ì ì¬ë¥¼ ìœ„í•œ **ì™„ë²½í•œ Markdown í¬ë§·**ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

**[í•„ìˆ˜ ìˆ˜í–‰ ê³¼ì œ]**
1. **ì™„ì „í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ:** í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  ì—…ë¬´ ê´€ë ¨ í…ìŠ¤íŠ¸(ë³¸ë¬¸, ì£¼ì„, ìº¡ì…˜ í¬í•¨)ë¥¼ ëˆ„ë½ ì—†ì´ ì „ì‚¬í•˜ì‹­ì‹œì˜¤.
2. **êµ¬ì¡°ì  ëª…ì‹œ:** ì œëª©(#)ê³¼ ë³¸ë¬¸, ë¦¬ìŠ¤íŠ¸(-)ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
3. **ë¶ˆí•„ìš”í•œ ë§ ìƒëµ:** "ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤"ì™€ ê°™ì€ ì„œë‘ë‚˜ ë§ºìŒë§ ì—†ì´, ì˜¤ì§ **Markdown ë³¸ë¬¸ ë‚´ìš©**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤."""



# Page Configuration
st.set_page_config(
    page_title="PDF Preprocessing with Qwen-VL",
    page_icon="ğŸ‘ï¸",
    layout="wide"
)

# Custom CSS
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; color: #333; }
    .stButton > button { border-radius: 8px; }
    .reportview-container { margin-top: -2em; }
    #MainMenu {visibility: hidden;}
    .stDeployButton {display:none;}
    footer {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

def get_base64_image(pix):
    """Convert PyMuPDF binary data to base64 string"""
    data = pix.tobytes("png")
    return base64.b64encode(data).decode('utf-8')

def parse_model_output(text):
    """
    Parse LLM output to separate <think>...</think> blocks from the actual response.
    Returns (thinking_content, response_content).
    """
    if not text:
        return "", ""
    
    # Check for thinking end tag FIRST (as per CLI robust fix)
    if '</think>' in text:
        parts = text.split('</think>')
        thinking = parts[0].replace('<think>', '').strip()
        response = parts[-1].strip()
        return thinking, response
        
    # Fallback to regex
    thinking_match = re.search(r'<think>(.*?)</think>', text, flags=re.IGNORECASE | re.DOTALL)
    thinking = thinking_match.group(1).strip() if thinking_match else ""
    
    response = re.sub(r'<think>.*?</think>', '', text, flags=re.IGNORECASE | re.DOTALL).strip()
    
    return thinking, response

def process_page_with_qwen(system_prompt, user_prompt, base64_image, previous_context=""):
    client = OpenAI(
        api_key=VLLM_API_KEY,
        base_url=VLLM_BASE_URL,
    )
    
    # Initialize list
    final_user_prompt_content = []

    # --- DEBUG LOGGING ---
    print("\n" + "="*50)
    print(f"ğŸš€ Processing Page (Context: {'Yes' if previous_context else 'No'})")
    print(f"ğŸ“· Image Size: {len(base64_image)} chars")
    
    # 1. Add Context (Previous Page)
    if previous_context:
        print(f"ğŸ”— Context Injected ({len(previous_context)} chars)")
        context_block = f"**[ì´ì „ í˜ì´ì§€ ë‚´ìš© (ë¬¸ë§¥ ìœ ì§€ìš©)]**\n{previous_context[-2000:]}\n\n**[ì§€ì‹œì‚¬í•­]**\nìœ„ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬, ë‹¤ìŒ í˜ì´ì§€ì˜ ë‚´ìš©ì„ ì´ì–´ì§€ëŠ” í˜•íƒœë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì‹œì˜¤."
        final_user_prompt_content.append({"type": "text", "text": context_block})
        
    # 2. Add Main Prompt & Image
    print(f"ğŸ“ User Prompt: {user_prompt[:100]}...")
    final_user_prompt_content.append({"type": "text", "text": user_prompt})
    final_user_prompt_content.append({
        "type": "image_url",
        "image_url": {
            "url": f"data:image/png;base64,{base64_image}"
        },
    })

    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": final_user_prompt_content,
        }
    ]

    # Extra body for thinking mode (if needed by model/vllm)
    extra_body = {
        "chat_template_kwargs": {"enable_thinking": True}
    }

    try:
        print("â³ Sending request to VLLM...")
        start_time = time.time()
        response = client.chat.completions.create(
            model=VLLM_MODEL,
            messages=messages,
            temperature=0.0,  # CLI uses 0.0
            max_tokens=8192,  # CLI uses 8192
            extra_body=extra_body
        )
        elapsed = time.time() - start_time
        print(f"âœ… Response received in {elapsed:.2f}s")
        
        raw_content = response.choices[0].message.content
        thinking, final_response = parse_model_output(raw_content)
        
        print(f"ğŸ§  Thinking: {len(thinking)} chars")
        print(f"ğŸ“„ Response: {len(final_response)} chars")
        if thinking:
            print(f"--- Thinking Preview ---\n{thinking[:200]}...\n------------------------")
        
        return thinking, final_response
    except Exception as e:
        print(f"âŒ Error: {e}")
        return "", f"Error: {e}"

def list_pdf_files():
    if not os.path.exists(PDF_DATA_DIR):
        os.makedirs(PDF_DATA_DIR)
        return []
    return [f for f in os.listdir(PDF_DATA_DIR) if f.lower().endswith('.pdf')]

def render_pdf_page(pdf_path, page_num):
    doc = fitz.open(pdf_path)
    page = doc.load_page(page_num)
    pix = page.get_pixmap(matrix=fitz.Matrix(1, 1)) # 1x1 Matrix (per CLI)
    return pix

def main():
    st.title("ğŸ‘ï¸ Visual PDF Preprocessor")
    st.markdown("Convert PDF pages to rich text (context + visual descriptions) using Qwen-VL.")

    # Sidebar Settings
    with st.sidebar:
        st.header("âš™ï¸ Settings")
        
        # File Selection
        pdf_files = list_pdf_files()
        uploaded_file = st.file_uploader("Upload New PDF", type="pdf")
        
        selected_pdf_name = st.selectbox(
            "Select PDF from 'test_pdf_data'", 
            options=["-- Select --"] + pdf_files
        )

        current_pdf_path = None
        if uploaded_file:
            # Save uploaded file to temp path or data dir
            save_path = os.path.join(PDF_DATA_DIR, uploaded_file.name)
            with open(save_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            current_pdf_path = save_path
            st.success(f"Saved {uploaded_file.name}")
            # Refresh list workaround or just use this path
        elif selected_pdf_name != "-- Select --":
            current_pdf_path = os.path.join(PDF_DATA_DIR, selected_pdf_name)

        st.divider()
        
        if st.button("ğŸš€ Process Entire Document", type="primary", use_container_width=True):
             st.session_state['batch_processing'] = True
             st.session_state['combined_result'] = "" # Reset

    if not current_pdf_path:
        st.info("ğŸ‘ˆ Please select or upload a PDF to start.")
        return

    # --- Main Content Area ---
    
    # Prompt Configuration (Prominent)
    st.header("ğŸ“ Prompt Configuration")
    st.markdown("These prompts control how the VLM interprets and translates your PDF pages.")
    
    col_sys, col_user = st.columns(2)
    with col_sys:
        system_prompt = st.text_area(
            "System Prompt",
            value=SYSTEM_PROMPT_DEFAULT,
            height=450
        )
    with col_user:
        user_prompt = st.text_area(
            "User Prompt",
            value=USER_PROMPT_DEFAULT,
            height=450
        )
    
    st.divider()

    # --- Document Processing ---
    doc = fitz.open(current_pdf_path)
    total_pages = len(doc)
    doc.close()

    # Check if batch processing was triggered
    if st.session_state.get('batch_processing', False):
        st.subheader("ğŸ“š Batch Processing")
        progress_bar = st.progress(0)
        status_text = st.empty()
        combined_text = ""
        
        last_page_text = ""
        
        for i in range(total_pages):
            status_text.text(f"Processing Page {i+1}/{total_pages}...")
            
            pix = render_pdf_page(current_pdf_path, i)
            base64_img = get_base64_image(pix)
            
            # Create a container for this page's result
            with st.container():
                st.markdown(f"### Page {i+1}")
                cols = st.columns([1, 2])
                
                # Column 1: Thumbnail
                with cols[0]:
                    st.image(pix.tobytes("png"), caption=f"Page {i+1}", use_container_width=True)
                
                # Column 2: Processing...
                with cols[1]:
                    with st.spinner("Analyzing..."):
                        # Pass context from previous page (last_page_text)
                        thinking, page_result = process_page_with_qwen(system_prompt, user_prompt, base64_img, previous_context=last_page_text)
                    
                    if thinking:
                        with st.expander(f"ğŸ§  Thinking Process", expanded=False):
                             st.code(thinking, language='text')
                             
                    st.markdown("**ğŸ“„ Extracted Content:**")
                    st.text_area(f"Output p{i+1}", value=page_result, height=200, label_visibility="collapsed")
            
            st.divider()
            
            combined_text += f"\n\n--- Page {i+1} ---\n\n"
            combined_text += page_result
            
            # Update last_page_text for next iteration context
            last_page_text = page_result
            
            progress_bar.progress((i + 1) / total_pages)
        
        st.session_state['combined_result'] = combined_text
        st.session_state['batch_processing'] = False
        status_text.success("Batch processing complete!")
        st.rerun()

    # Display Results
    if 'combined_result' in st.session_state and st.session_state['combined_result']:
        st.subheader("ğŸ“‘ Combined Document Output")
        st.text_area("Full Document Markdown", value=st.session_state['combined_result'], height=800)
        
        if st.button("ğŸ’¾ Save All to .txt"):
            output_filename = f"processed_{os.path.basename(current_pdf_path).replace('.pdf', '')}_FULL.txt"
            with open(os.path.join(PDF_DATA_DIR, output_filename), "w") as f:
                f.write(st.session_state['combined_result'])
            st.success(f"Saved to {output_filename}")
            
        if st.button("ï¿½ Clear Results"):
             del st.session_state['combined_result']
             st.rerun()
    else:
        # Show preview when no results yet
        st.subheader(f"ğŸ“„ Document Preview ({total_pages} pages)")
        page_num = st.slider("Preview Page", min_value=1, max_value=total_pages, value=1) - 1
        pix = render_pdf_page(current_pdf_path, page_num)
        st.image(pix.tobytes("png"), caption=f"Page {page_num + 1} / {total_pages}", use_container_width=True)

if __name__ == "__main__":
    main()